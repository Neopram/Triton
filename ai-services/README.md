# Phi-3 Local Maritime AI Service

This service provides local processing of maritime queries using the Phi-3 mini model, optimized for offline usage and low-resource environments.

## Directory Structure

- Service main file: `C:\Users\feder\Desktop\TritonAI\ai-services\phi3\phi3_service.py`
- Environment config: `C:\Users\feder\Desktop\TritonAI\ai-services\phi3\.env`
- Requirements file: `C:\Users\feder\Desktop\TritonAI\ai-services\phi3\requirements.txt`

## Features

- Local processing of maritime queries without cloud dependency
- Optimized for resource-constrained environments
- Offline mode capabilities for disconnected operations
- Efficient memory management and model quantization
- Response caching for improved performance
- Seamless integration with Triton's AI orchestrator

## Requirements

- Python 3.8+
- 8GB+ RAM (16GB recommended)
- CUDA compatible GPU optional but recommended
- 2GB+ disk space for model storage

## Installation

1. Navigate to the phi3 service directory: